From 0bbcfef0dddebe32e6e671f6479965179a69e479 Mon Sep 17 00:00:00 2001
From: Javad Rahimipetroudi <javad.rahimipetroudi@mind.be>
Date: Tue, 10 Dec 2024 16:45:59 +0100
Subject: [PATCH 10/14] Allow page sizes multiple of 4096

Signed-off-by: Javad Rahimipetroudi <javad.rahimipetroudi@mind.be>
---
 drivers/iommu/sun50i-iommu.c | 41 ++++++++++++++++++++++++++----------
 1 file changed, 30 insertions(+), 11 deletions(-)

diff --git a/drivers/iommu/sun50i-iommu.c b/drivers/iommu/sun50i-iommu.c
index 8d8f11854676..a3085bed7aaa 100644
--- a/drivers/iommu/sun50i-iommu.c
+++ b/drivers/iommu/sun50i-iommu.c
@@ -598,10 +598,12 @@ static int sun50i_iommu_map(struct iommu_domain *domain, unsigned long iova,
 {
 	struct sun50i_iommu_domain *sun50i_domain = to_sun50i_domain(domain);
 	struct sun50i_iommu *iommu = sun50i_domain->iommu;
-	u32 pte_index;
+	u32 pte_index, pages, i;
 	u32 *page_table, *pte_addr;
 	int ret = 0;
 
+	pages = size / SPAGE_SIZE;
+
 	/* the IOMMU can only handle 32-bit addresses, both input and output */
 	if ((uint64_t)paddr >> 32) {
 		ret = -EINVAL;
@@ -617,6 +619,7 @@ static int sun50i_iommu_map(struct iommu_domain *domain, unsigned long iova,
 	}
 
 	pte_index = sun50i_iova_get_pte_index(iova);
+#if 0
 	pte_addr = &page_table[pte_index];
 	if (unlikely(sun50i_pte_is_page_valid(*pte_addr))) {
 		phys_addr_t page_phys = sun50i_pte_get_page_address(*pte_addr);
@@ -626,9 +629,24 @@ static int sun50i_iommu_map(struct iommu_domain *domain, unsigned long iova,
 		ret = -EBUSY;
 		goto out;
 	}
-
-	*pte_addr = sun50i_mk_pte(paddr, prot);
-	sun50i_table_flush(sun50i_domain, pte_addr, 1);
+#endif
+	for (i = 0; i < pages; i++) {
+		pte_addr = &page_table[pte_index + i];
+		if (unlikely(sun50i_pte_is_page_valid(*pte_addr))) {
+			phys_addr_t page_phys = sun50i_pte_get_page_address(*pte_addr);
+			dev_err(iommu->dev,
+				"iova %pad already mapped to %pa cannot remap to %pa prot: %#x\n",
+				&iova, &page_phys, &paddr, prot);
+			ret = -EBUSY;
+			goto out;
+		}
+		*pte_addr = sun50i_mk_pte(paddr, prot);
+		paddr += SPAGE_SIZE;
+         }
+
+//	*pte_addr = sun50i_mk_pte(paddr, prot);
+	sun50i_table_flush(sun50i_domain, &page_table[pte_index], pages);
+	//sun50i_table_flush(sun50i_domain, pte_addr, 1);
 	*mapped = size;
 
 out:
@@ -641,7 +659,7 @@ static size_t sun50i_iommu_unmap(struct iommu_domain *domain, unsigned long iova
 	struct sun50i_iommu_domain *sun50i_domain = to_sun50i_domain(domain);
 	phys_addr_t pt_phys;
 	u32 *pte_addr;
-	u32 dte;
+	u32 dte, pages, i;
 
 	dte = sun50i_domain->dt[sun50i_iova_get_dte_index(iova)];
 	if (!sun50i_dte_is_pt_valid(dte))
@@ -650,13 +668,14 @@ static size_t sun50i_iommu_unmap(struct iommu_domain *domain, unsigned long iova
 	pt_phys = sun50i_dte_get_pt_address(dte);
 	pte_addr = (u32 *)phys_to_virt(pt_phys) + sun50i_iova_get_pte_index(iova);
 
-	if (!sun50i_pte_is_page_valid(*pte_addr))
-		return 0;
+	for (i = 0; i < pages; i++)
+		if (!sun50i_pte_is_page_valid(*pte_addr))
+			return 0;
 
-	memset(pte_addr, 0, sizeof(*pte_addr));
-	sun50i_table_flush(sun50i_domain, pte_addr, 1);
+	memset(pte_addr, 0, sizeof(*pte_addr) * pages);
+	sun50i_table_flush(sun50i_domain, pte_addr, pages);
 
-	return SZ_4K;
+	return size;
 }
 
 static phys_addr_t sun50i_iommu_iova_to_phys(struct iommu_domain *domain,
@@ -842,7 +861,7 @@ static int sun50i_iommu_of_xlate(struct device *dev,
 
 static const struct iommu_ops sun50i_iommu_ops = {
 	.identity_domain = &sun50i_iommu_identity_domain,
-	.pgsize_bitmap	= SZ_4K,
+	.pgsize_bitmap	= 0x1ff000,
 	.device_group	= generic_single_device_group,
 	.domain_alloc_paging = sun50i_iommu_domain_alloc_paging,
 	.of_xlate	= sun50i_iommu_of_xlate,
-- 
2.47.1

